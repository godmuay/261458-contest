import tensorflow as tf
from tensorflow.keras import layers, models, Input
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import AdamW
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import cv2
import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# ğŸ—ï¸ à¹‚à¸«à¸¥à¸” ResNet50 à¹€à¸›à¹‡à¸™ Feature Extractor
def create_feature_extractor():
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
    
    # âœ… à¸›à¸¥à¸”à¸¥à¹‡à¸­à¸„à¸šà¸²à¸‡à¸Šà¸±à¹‰à¸™à¹ƒà¸«à¹‰ Train à¹„à¸”à¹‰
    for layer in base_model.layers[-30:]:  # Unfreeze 30 à¸Šà¸±à¹‰à¸™à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢
        layer.trainable = True
    
    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu')
    ])
    
    return model

# ğŸ”„ à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸ à¸²à¸ (à¹ƒà¸Šà¹‰ Cosine Similarity)
def create_comparison_model():
    feature_extractor = create_feature_extractor()
    
    input_1 = Input(shape=(128, 128, 3))
    input_2 = Input(shape=(128, 128, 3))

    feature_1 = feature_extractor(input_1)
    feature_2 = feature_extractor(input_2)
    
    # âœ… à¹ƒà¸Šà¹‰ Cosine Similarity à¹à¸—à¸™ Absolute Difference
    cosine_similarity = layers.Dot(axes=1, normalize=True)([feature_1, feature_2])
    
    combined = layers.Dense(128, activation='relu')(cosine_similarity)
    combined = layers.BatchNormalization()(combined)
    combined = layers.Dropout(0.5)(combined)
    output = layers.Dense(3, activation='softmax')(combined)  # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ 3 Class (1, 2, 3)
    
    model = models.Model(inputs=[input_1, input_2], outputs=output)
    model.compile(optimizer=AdamW(learning_rate=0.0001, weight_decay=1e-4), 
                  loss='sparse_categorical_crossentropy', 
                  metrics=['accuracy'])
    return model

# ğŸ“‚ à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
def load_data(csv_file, image_dir):
    df = pd.read_csv(csv_file)
    X1, X2, y = [], [], []
    
    for _, row in df.iterrows():
        img1_path = os.path.join(image_dir, row['Image 1'])
        img2_path = os.path.join(image_dir, row['Image 2'])
        
        if not os.path.exists(img1_path) or not os.path.exists(img2_path):
            print(f"âš ï¸ Missing {img1_path} or {img2_path}")
            continue
        
        img1 = cv2.imread(img1_path)
        img2 = cv2.imread(img2_path)

        if img1 is None or img2 is None:
            print(f"âš ï¸ Cannot read {img1_path} or {img2_path}")
            continue
        
        img1 = cv2.resize(img1, (128, 128)) / 255.0
        img2 = cv2.resize(img2, (128, 128)) / 255.0
        X1.append(img1)
        X2.append(img2)
        y.append(row['Winner'])  # à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ 1, 2, 3 à¸•à¸£à¸‡à¹†
    
    return np.array(X1), np.array(X2), np.array(y)

# ğŸ“ à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸˜à¹„à¸Ÿà¸¥à¹Œ
dataset_csv = "D:/contest/Dataset_for_development-20250304T203703Z-004/Dataset_for_development/data_from_questionaire.csv"
image_dir = "D:/contest/Dataset_for_development-20250304T203703Z-004/Dataset_for_development/Questionair_Images"

# ğŸ“Š à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Train/Test
X1, X2, y = load_data(dataset_csv, image_dir)
X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(X1, X2, y, test_size=0.2, random_state=42)

# ğŸ·ï¸ à¸›à¸£à¸±à¸šà¸ªà¸¡à¸”à¸¸à¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}
print("ğŸ“Š Class Weights:", class_weight_dict)

# ğŸ¨ Data Augmentation
data_gen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    brightness_range=[0.7, 1.3],
    zoom_range=0.3,
    horizontal_flip=True
)

def augment_data(X1, X2, y):
    X1_aug, X2_aug, y_aug = [], [], []
    for i in range(len(X1)):
        img1_aug = data_gen.random_transform(X1[i])
        img2_aug = data_gen.random_transform(X2[i])
        X1_aug.append(img1_aug)
        X2_aug.append(img2_aug)
        y_aug.append(y[i])
    return np.array(X1_aug), np.array(X2_aug), np.array(y_aug)

X1_train, X2_train, y_train = augment_data(X1_train, X2_train, y_train)

# ğŸ—ï¸ à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥
model = create_comparison_model()
model.summary()

# ğŸ”„ Learning Rate Scheduling
lr_schedule = LearningRateScheduler(lambda epoch: 1e-3 * 0.95 ** epoch)  # à¹ƒà¸Šà¹‰ Decay à¹à¸—à¸™

# ğŸ“Œ à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸‰à¸à¸²à¸°à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”
checkpoint = ModelCheckpoint('compare_model_best1111.keras', monitor='val_accuracy', save_best_only=True, mode='max')

# ğŸš€ à¹€à¸£à¸´à¹ˆà¸¡ Train
history = model.fit(
    [X1_train, X2_train], y_train,
    epochs=30, batch_size=20,
    validation_data=([X1_test, X2_test], y_test),
    class_weight=class_weight_dict,
    callbacks=[checkpoint, lr_schedule]
)

# ğŸ¯ à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸ˆà¸²à¸ Test Set
y_pred = model.predict([X1_test, X2_test])
y_pred_classes = np.argmax(y_pred, axis=1)  # à¹ƒà¸Šà¹‰ argmax à¸«à¸²à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸”

# ğŸ“Œ Confusion Matrix
cm = confusion_matrix(y_test, y_pred_classes)

# ğŸ”¥ à¹à¸ªà¸”à¸‡ Confusion Matrix à¸”à¹‰à¸§à¸¢ Heatmap
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Class 1', 'Class 2', 'Class 3'], yticklabels=['Class 1', 'Class 2', 'Class 3'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ğŸ“Š à¹à¸ªà¸”à¸‡ Classification Report
print("ğŸ“Œ Classification Report:\n", classification_report(y_test, y_pred_classes))
